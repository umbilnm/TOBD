{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kill4\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kill4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Этот', 'коктейль', 'готовлю', 'из', 'замороженной', 'клубники', '.', 'Если', 'клубника', 'свежая', ',', 'то', 'добавляю', 'перепелиное', 'яйцо', ',', 'благодаря', 'этому', 'коктейль', 'получается', 'устойчиво', 'густым', '.']),\n",
       "       list(['Быстро', 'и', 'вкусно', '.']),\n",
       "       list(['Сытный', ',', 'овощной', 'салатик', ',', 'пальчики', 'оближете', '.']),\n",
       "       ...,\n",
       "       list(['Мое', 'любимое', 'блюдо', 'лазанья', '.', 'Но', 'кушать', 'только', 'фарш', 'уже', 'поднадоело', ',', 'потому', 'добавляю', 'в', 'красный', 'соус', 'овощи', '.', 'Соус', 'видоизменен', ',', 'потому', 'это', 'уже', 'будет', 'не', 'тот', 'самый', 'Болоньез', '.', 'Но', 'подойдет', 'он', 'ко', 'всему', '.']),\n",
       "       list(['Прошлым', 'летом', 'варила', 'варенье', 'из', 'одуванчиков', 'по', 'рецептам', 'нашего', 'сайта', ',', 'а', 'сейчас', 'попробовала', 'новый', 'вариант', '.', 'Благодарю', 'Сергея', 'Самойлова', ',', 'его', 'рецепт', 'взяла', 'за', 'основу', ',', 'немного', 'изменив', 'приготовление', '.']),\n",
       "       list(['-', 'И', 'три', 'корочки', 'хлеба', '!', '-', 'сделал', 'заказ', 'Буратино', 'в', 'таверне', 'по', 'дороге', 'в', 'Страну', 'Дураков', '.', '-', 'Ну', 'хотя', 'бы', '...', 'под', 'соусом', 'болоньез', ',', 'per', 'favore', '!', '-', 'попросил', 'бы', 'Пиноккио', '.', 'Ну', ',', 'а', 'почему', 'бы', 'и', 'нет', '?', '-', 'подумала', 'я', '.', '``', 'Говорят', ',', 'под', 'Новый', 'год', ',', 'Что', 'ни', 'пожелаешь', ':', 'Всe', 'всегда', 'произойдeт', ',', 'Всe', 'всегда', 'сбывается', '!', '...', '!', 'А', 'мы', 'подружим', '-', 'наших', 'таких', 'одинаковых', 'и', 'таких', 'разных', '-', 'задорных', 'мальчишек', 'из', 'разных', 'стран', 'и', 'сказок', 'в', 'нашем', 'рецепте', '.', '(', 'Лучше', 'поздно', ',', 'чем', 'никогда', ',', 'правда', 'ведь', '?', ')', 'Итак', ',', 'под', 'Новый', 'год', 'волшебная', 'сказка', 'превращается', 'в', 'настоящее', 'чудо', '!'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ru_recipes_sample.csv'); df\n",
    "s1 = pd.Series(df.description.values)\n",
    "arr2 = s1.values.copy()\n",
    "s1 = s1.apply(lambda x: word_tokenize(x))\n",
    "arr = np.array(s1)\n",
    "\n",
    "words = []\n",
    "for lst in arr:\n",
    "    for word in lst:\n",
    "        if word.isalpha() and word not in words:\n",
    "            words.append(word)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)\n",
    "words = np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>маринованных</td>\n",
       "      <td>кольца</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>понадобиться</td>\n",
       "      <td>местах</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Русская</td>\n",
       "      <td>треугольники</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Выглядит</td>\n",
       "      <td>Крабовые</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>финиками</td>\n",
       "      <td>годы</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1             2  distance\n",
       "0  маринованных        кольца        11\n",
       "1  понадобиться        местах        11\n",
       "2       Русская  треугольники        11\n",
       "3      Выглядит      Крабовые         8\n",
       "4      финиками          годы         8"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series(words)\n",
    "df = pd.DataFrame(data = {'1': s1.sample(n = 5).values, '2' : s1.sample(n = 5).values})\n",
    "array = []\n",
    "for i in range(5):\n",
    "    array.append(edit_distance(df['1'][i], df['2'][i]))\n",
    "df['distance'] = array; df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(word:str, k:int):\n",
    "    s1 = pd.Series(words)\n",
    "    distances = s1.apply(lambda x: edit_distance(word, x, substitution_cost=2))\n",
    "    indxs = np.argsort(np.array(distances))[:k]\n",
    "    return words[indxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['булка', 'белка', 'булку'], dtype='<U21')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn('булка', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "snb_stemmer_ru = SnowballStemmer('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Этот</th>\n",
       "      <td>этот</td>\n",
       "      <td>этот</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>коктейль</th>\n",
       "      <td>коктейл</td>\n",
       "      <td>коктейль</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>готовлю</th>\n",
       "      <td>готовл</td>\n",
       "      <td>готовить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>из</th>\n",
       "      <td>из</td>\n",
       "      <td>из</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>замороженной</th>\n",
       "      <td>заморожен</td>\n",
       "      <td>заморозить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сбывается</th>\n",
       "      <td>сбыва</td>\n",
       "      <td>сбываться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>подружим</th>\n",
       "      <td>подруж</td>\n",
       "      <td>подружить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>одинаковых</th>\n",
       "      <td>одинаков</td>\n",
       "      <td>одинаковый</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>задорных</th>\n",
       "      <td>задорн</td>\n",
       "      <td>задорный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>мальчишек</th>\n",
       "      <td>мальчишек</td>\n",
       "      <td>мальчишка</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             stemmed_word normalized_word\n",
       "word                                     \n",
       "Этот                 этот            этот\n",
       "коктейль          коктейл        коктейль\n",
       "готовлю            готовл        готовить\n",
       "из                     из              из\n",
       "замороженной    заморожен      заморозить\n",
       "...                   ...             ...\n",
       "сбывается           сбыва       сбываться\n",
       "подружим           подруж       подружить\n",
       "одинаковых       одинаков      одинаковый\n",
       "задорных           задорн        задорный\n",
       "мальчишек       мальчишек       мальчишка\n",
       "\n",
       "[17890 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data = words, columns=['word']);\n",
    "df1['stemmed_word'] = df1['word'].apply(lambda x: snb_stemmer_ru.stem(x))\n",
    "df1['normalized_word'] = df1['word'].apply(lambda x: morph.parse(x)[0].normal_form)\n",
    "df1 = df1.set_index('word')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128822"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = []\n",
    "for lst in arr:\n",
    "    for word in lst:\n",
    "        arr2.append(word)\n",
    "before_obr = arr2.copy()\n",
    "len(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69349"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_stop_words = stopwords.words('russian')\n",
    "p = re.compile('^[а-яА-ЯёЁ*&]')\n",
    "arr2 = [i for i in arr2 if p.search(i)]\n",
    "ru_stop_words = stopwords.words('russian')\n",
    "a = [w.lower() for w in arr2 if w.lower() not in ru_stop_words]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля стоп-слов: 0.32368831675443727\n"
     ]
    }
   ],
   "source": [
    "print(f'Доля стоп-слов: {(len(arr2) - len(a))/ len(arr2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 до удаления стоп-слов:\n",
      "и        4822\n",
      "в        2304\n",
      "с        1850\n",
      "на       1504\n",
      "не       1427\n",
      "очень    1123\n",
      "из        977\n",
      "я         752\n",
      "что       732\n",
      "для       686\n",
      "dtype: int64\n",
      "\n",
      "Топ-10 после удаления стоп-слов:\n",
      "очень          1608\n",
      "рецепт          869\n",
      "это             733\n",
      "блюдо           525\n",
      "вкусный         461\n",
      "просто          436\n",
      "вкусно          378\n",
      "приготовить     344\n",
      "вкус            323\n",
      "салат           313\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "before_obr = [i for i in before_obr if p.search(i)]\n",
    "do_udal = pd.Series(before_obr)\n",
    "posle = pd.Series(a)\n",
    "print(f'Топ-10 до удаления стоп-слов:\\n{do_udal.value_counts()[:10]}')\n",
    "print()\n",
    "print(f'Топ-10 после удаления стоп-слов:\\n{posle.value_counts()[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
